{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running Jax training loops, how do I make ballpark estimates of the GPU memory usage? GPU memory is one of the big bottlenecks when it comes to end-to-end deep RL training using Jax.\n",
    "\n",
    "(Specifically for the case of `train_single_task_pushworld_all_hparam_lr.py`)\n",
    "\n",
    "All the different types of data:\n",
    "\n",
    "- PushWorld puzzles\n",
    "- Transitions\n",
    "- Model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimyoungjin/Projects/monkey/xland-minigrid/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from functools import partial\n",
    "from typing import List, Optional\n",
    "\n",
    "import imageio\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import optax\n",
    "import orbax\n",
    "import pyrallis\n",
    "import wandb\n",
    "from flax.jax_utils import replicate, unreplicate\n",
    "from flax.training import orbax_utils\n",
    "from flax.training.train_state import TrainState\n",
    "import xminigrid.envs.pushworld as pushworld\n",
    "from xminigrid.envs.pushworld.benchmarks import BenchmarkAll\n",
    "\n",
    "from train_single_task_pushworld_all_hparam_lr import TrainConfig\n",
    "from train_single_task_pushworld_all_hparam_lr import make_states\n",
    "from utils_pushworld_all import Transition, calculate_gae, rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num devices: 1, Num updates: 2\n"
     ]
    }
   ],
   "source": [
    "config = TrainConfig(\n",
    "    benchmark_id=\"level0_transformed_all\",\n",
    "    total_timesteps=1_000_000,\n",
    "    num_envs=4096,\n",
    "    num_steps=100,\n",
    "    # num_train=1000,\n",
    "    # num_test=100,\n",
    "    enable_bf16=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pushworld.load_all_benchmark(config.benchmark_id)\n",
    "\n",
    "puzzle_rng = jax.random.key(config.puzzle_seed)\n",
    "train_rng, test_rng = jax.random.split(puzzle_rng)\n",
    "\n",
    "if config.num_train is not None:\n",
    "    assert config.num_train <= benchmark.num_train_puzzles(), (\n",
    "        \"num_train is larger than num train available in benchmark\"\n",
    "    )\n",
    "    perm = jax.random.permutation(train_rng, benchmark.num_train_puzzles())\n",
    "    idxs = perm[: config.num_train]\n",
    "    benchmark = benchmark.replace(train_puzzles=benchmark.train_puzzles[idxs])\n",
    "else:\n",
    "    config.num_train = benchmark.num_train_puzzles()\n",
    "\n",
    "if config.num_test is not None:\n",
    "    assert config.num_test <= benchmark.num_test_puzzles(), \"num_test is larger than num test available in benchmark\"\n",
    "    perm = jax.random.permutation(test_rng, benchmark.num_test_puzzles())\n",
    "    idxs = perm[: config.num_test]\n",
    "    benchmark = benchmark.replace(test_puzzles=benchmark.test_puzzles[idxs])\n",
    "else:\n",
    "    config.num_test = benchmark.num_test_puzzles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytree_megabytes(tree):\n",
    "    def leaf_bytes(x):\n",
    "        if isinstance(x, (jnp.ndarray, np.ndarray)):\n",
    "            return x.size * x.dtype.itemsize\n",
    "        return 0\n",
    "\n",
    "    nbytes = sum(jtu.tree_leaves(jtu.tree_map(leaf_bytes, tree)))\n",
    "    return nbytes / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PushWorld puzzles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.2208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT TRAJECTORIES\n",
    "def _env_step(runner_state, _):\n",
    "    rng, train_state, prev_timestep, prev_action, prev_reward, prev_hstate = runner_state\n",
    "\n",
    "    # SELECT ACTION\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    dist, value, hstate = train_state.apply_fn(\n",
    "        train_state.params,\n",
    "        {\n",
    "            # [batch_size, seq_len=1, ...]\n",
    "            \"obs\": prev_timestep.observation[:, None],\n",
    "            \"prev_action\": prev_action[:, None],\n",
    "            \"prev_reward\": prev_reward[:, None],\n",
    "        },\n",
    "        prev_hstate,\n",
    "    )\n",
    "    action, log_prob = dist.sample_and_log_prob(seed=_rng)\n",
    "    # squeeze seq_len where possible\n",
    "    action, value, log_prob = action.squeeze(1), value.squeeze(1), log_prob.squeeze(1)\n",
    "\n",
    "    # STEP ENV\n",
    "    timestep = jax.vmap(env.step, in_axes=(None, 0, 0))(puzzle_env_params, prev_timestep, action)\n",
    "    transition = Transition(\n",
    "        done=timestep.last(),\n",
    "        action=action,\n",
    "        value=value,\n",
    "        reward=timestep.reward,\n",
    "        log_prob=log_prob,\n",
    "        obs=prev_timestep.observation,\n",
    "        prev_action=prev_action,\n",
    "        prev_reward=prev_reward,\n",
    "    )\n",
    "    runner_state = (rng, train_state, timestep, action, timestep.reward, hstate)\n",
    "    return runner_state, transition\n",
    "\n",
    "\n",
    "rng, env, env_params, benchmark, init_hstate, network, network_params = make_states(config)\n",
    "\n",
    "\n",
    "def linear_schedule(count):\n",
    "    frac = 1.0 - (count // (config.num_minibatches * config.update_epochs)) / config.num_updates\n",
    "    return config.lr * frac\n",
    "\n",
    "\n",
    "tx = optax.chain(\n",
    "    optax.clip_by_global_norm(config.max_grad_norm),\n",
    "    optax.inject_hyperparams(optax.adam)(learning_rate=linear_schedule, eps=1e-8),  # eps=1e-5\n",
    ")\n",
    "train_state = TrainState.create(apply_fn=network.apply, params=network_params, tx=tx)\n",
    "\n",
    "rng, _rng = jax.random.split(rng)\n",
    "reset_rng = jax.random.split(_rng, config.num_envs_per_device)\n",
    "puzzle_env_params = env_params.replace(benchmark=benchmark)\n",
    "timestep = jax.vmap(env.reset, in_axes=(None, 0))(puzzle_env_params, reset_rng)\n",
    "prev_action = jnp.zeros(config.num_envs_per_device, dtype=jnp.int32)\n",
    "prev_reward = jnp.zeros(config.num_envs_per_device)\n",
    "\n",
    "\n",
    "runner_state = (rng, train_state, timestep, prev_action, prev_reward, init_hstate)\n",
    "# transitions: [seq_len, batch_size, ...]\n",
    "runner_state, transitions = jax.lax.scan(_env_step, runner_state, None, config.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320.1408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, train_state, timestep, prev_action, prev_reward, hstate = runner_state\n",
    "# calculate value of the last step for bootstrapping\n",
    "_, last_val, _ = train_state.apply_fn(\n",
    "    train_state.params,\n",
    "    {\n",
    "        \"obs\": timestep.observation[:, None],\n",
    "        \"prev_action\": prev_action[:, None],\n",
    "        \"prev_reward\": prev_reward[:, None],\n",
    "    },\n",
    "    hstate,\n",
    ")\n",
    "advantages, targets = calculate_gae(transitions, last_val.squeeze(1), config.gamma, config.gae_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_hstate = init_hstate[None, :]\n",
    "\n",
    "rng, _rng = jax.random.split(rng)\n",
    "permutation = jax.random.permutation(_rng, config.num_envs_per_device)\n",
    "# [seq_len, batch_size, ...]\n",
    "batch = (init_hstate, transitions, advantages, targets)\n",
    "# [batch_size, seq_len, ...], as our model assumes\n",
    "batch = jtu.tree_map(lambda x: x.swapaxes(0, 1), batch)\n",
    "\n",
    "# init_hstate: num_envs, 1, 1, 1024\n",
    "# advantages: num_envs, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330.167808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_batch = jtu.tree_map(lambda x: jnp.take(x, permutation, axis=0), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.014016"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(shuffled_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatches = jtu.tree_map(lambda x: jnp.reshape(x, (config.num_minibatches, -1) + x.shape[1:]), shuffled_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.014016"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, _rng = jax.random.split(rng)\n",
    "permutation = jax.random.permutation(_rng, config.num_envs_per_device)\n",
    "# [seq_len, batch_size, ...]\n",
    "batch = (init_hstate, transitions, advantages, targets)\n",
    "# [batch_size, seq_len, ...], as our model assumes\n",
    "batch = jtu.tree_map(lambda x: x.swapaxes(0, 1), batch)\n",
    "\n",
    "shuffled_batch = jtu.tree_map(lambda x: jnp.take(x, permutation, axis=0), batch)\n",
    "# [num_minibatches, minibatch_size, ...]\n",
    "minibatches = jtu.tree_map(lambda x: jnp.reshape(x, (config.num_minibatches, -1) + x.shape[1:]), shuffled_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reset_rng = jax.random.key(config.eval_seed)\n",
    "eval_test_rng, eval_train_rng = jax.random.split(eval_reset_rng)\n",
    "\n",
    "eval_train_reset_rng = jax.random.split(eval_train_rng, num=config.num_train)\n",
    "eval_train_puzzles = benchmark.get_train_puzzles()\n",
    "eval_train_stats = jax.vmap(rollout, in_axes=(0, None, None, 0, None, None, None))(\n",
    "    eval_train_reset_rng,\n",
    "    env,\n",
    "    puzzle_env_params,\n",
    "    eval_train_puzzles,\n",
    "    train_state,\n",
    "    # TODO: make this as a static method mb?\n",
    "    jnp.zeros((1, config.rnn_num_layers, config.rnn_hidden_dim), dtype=jnp.bfloat16 if config.enable_bf16 else None),\n",
    "    1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytree_megabytes(eval_train_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
