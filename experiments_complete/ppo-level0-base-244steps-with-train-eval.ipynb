{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"886d0e5f","cell_type":"markdown","source":"# Single-task PushWorld Training","metadata":{}},{"id":"ac34fb8b-8c04-4bf5-8d12-5f0f70fddeb1","cell_type":"code","source":"# WandB run: https://wandb.ai/kimyoungjin-nus/PushWorld/runs/1lrafh19/overview","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ceb14d6a","cell_type":"code","source":"# Install if needed\n!pip install \"xminigrid[baselines] @ git+https://github.com/jugheadjones10/xland-minigrid.git\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:02.598685Z","iopub.execute_input":"2025-07-28T09:12:02.599472Z","iopub.status.idle":"2025-07-28T09:12:36.642938Z","shell.execute_reply.started":"2025-07-28T09:12:02.599421Z","shell.execute_reply":"2025-07-28T09:12:36.642227Z"}},"outputs":[{"name":"stdout","text":"Collecting xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git (from xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Cloning https://github.com/jugheadjones10/xland-minigrid.git to /tmp/pip-install-c1j5j3js/xminigrid_0dcdcf0889b4424d8491abfb108ba726\n  Running command git clone --filter=blob:none --quiet https://github.com/jugheadjones10/xland-minigrid.git /tmp/pip-install-c1j5j3js/xminigrid_0dcdcf0889b4424d8491abfb108ba726\n  Resolved https://github.com/jugheadjones10/xland-minigrid.git to commit d132c0a6310cf25fd14c611dc5612c51087c2be9\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: flax>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.10.6)\nRequirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (14.0.0)\nRequirement already satisfied: chex>=0.1.85 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.89)\nRequirement already satisfied: imageio>=2.31.2 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.37.0)\nRequirement already satisfied: imageio-ffmpeg>=0.4.9 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.6.0)\nCollecting libcst<2.0.0,>=1.8.2 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading libcst-1.8.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: nbformat<6.0.0,>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (5.10.4)\nCollecting pytest<9.0.0,>=8.4.1 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting gradio<6.0.0,>=5.38.1 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading gradio-5.38.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: matplotlib>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.7.2)\nRequirement already satisfied: wandb>=0.15.10 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.20.1)\nCollecting pyrallis>=0.3.1 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading pyrallis-0.3.1-py3-none-any.whl.metadata (17 kB)\nCollecting distrax>=0.1.5 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading distrax-0.1.5-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: optax>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.2.5)\nCollecting orbax>=0.1.9 (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading orbax-0.1.9.tar.gz (1.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.66.4 in /usr/local/lib/python3.11/dist-packages (from xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.67.1)\nRequirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.4.0)\nRequirement already satisfied: typing_extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.14.0)\nRequirement already satisfied: jax>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.5.2)\nRequirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.5.1)\nRequirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.26.4)\nRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.0.0)\nRequirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.25.0)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.1.1)\nRequirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.11.16)\nRequirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.74)\nRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (6.0.2)\nRequirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.9)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.9.0)\nCollecting brotli>=1.1.0 (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.115.13)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.6.0)\nCollecting gradio-client==1.11.0 (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git)\n  Downloading gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.33.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.10.18)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (11.2.1)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.11.7)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.0.20)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.12.0)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.16.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.34.3)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.5.1)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (15.0.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.9.0.post0)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.24.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (5.8.1)\nRequirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (5.7.1)\nRequirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyrallis>=0.3.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.9.0)\nRequirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.4.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.1.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.4.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.6.0)\nRequirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.4.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.19.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.4.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.0.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (8.2.1)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (7.0.0)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.32.4)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.31.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.3.6)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.0.12)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.18.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.1.5)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.15.3)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat<6.0.0,>=5.10.4->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.25.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.4.1)\nRequirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.12.2)\nRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.6.0)\nRequirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.12.3)\nRequirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.20.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.2->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2.5.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (4.4.2)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.1.1)\nRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.6.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (0.1.9)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<6.0.0,>=5.38.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.5.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis>=0.3.1->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.1.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (5.0.2)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability>=0.15.0->distrax>=0.1.5->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.17.2)\nRequirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (6.5.2)\nRequirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.8.0->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (3.23.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.1->chex>=0.1.85->xminigrid@ git+https://github.com/jugheadjones10/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/jugheadjones10/xland-minigrid.git) (2024.2.0)\nDownloading distrax-0.1.5-py3-none-any.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-5.38.2-py3-none-any.whl (59.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.5/324.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libcst-1.8.2-cp311-cp311-manylinux_2_28_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\nDownloading pytest-8.4.1-py3-none-any.whl (365 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.5/365.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: xminigrid, orbax\n  Building wheel for xminigrid (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for xminigrid: filename=xminigrid-0.0.1-py3-none-any.whl size=84345 sha256=0c7e3fa4e2a635274cd0f84f106300b4065a73c26b2313bd844890cfb363e8ba\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0g5m9tuy/wheels/c2/b5/bf/e756bdc2d97074ee0b3a8a84e93d98918ace1438297a7d126a\n  Building wheel for orbax (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for orbax: filename=orbax-0.1.9-py3-none-any.whl size=1496 sha256=d845876c4ebc0c66a4e0da465d63c5da29dfdb92ae5fd7bfe64e61ca698b2f48\n  Stored in directory: /root/.cache/pip/wheels/c3/db/68/3b3d5f58479cc8823c04f14722958d959580e649d5c31a6405\nSuccessfully built xminigrid orbax\nInstalling collected packages: brotli, pytest, libcst, pyrallis, gradio-client, gradio, xminigrid, orbax, distrax\n  Attempting uninstall: pytest\n    Found existing installation: pytest 8.3.5\n    Uninstalling pytest-8.3.5:\n      Successfully uninstalled pytest-8.3.5\n  Attempting uninstall: gradio-client\n    Found existing installation: gradio_client 1.10.1\n    Uninstalling gradio_client-1.10.1:\n      Successfully uninstalled gradio_client-1.10.1\n  Attempting uninstall: gradio\n    Found existing installation: gradio 5.31.0\n    Uninstalling gradio-5.31.0:\n      Successfully uninstalled gradio-5.31.0\nSuccessfully installed brotli-1.1.0 distrax-0.1.5 gradio-5.38.2 gradio-client-1.11.0 libcst-1.8.2 orbax-0.1.9 pyrallis-0.3.1 pytest-8.4.1 xminigrid-0.0.1\n","output_type":"stream"}],"execution_count":3},{"id":"a248848c","cell_type":"code","source":"import os\nimport shutil\nimport time #noqa\nimport os #noqa\nimport math # noqa\nfrom typing import TypedDict, Optional, Literal #noqa\nimport numpy as np #noqa\nimport importlib #noqa\nimport os #noqa\nimport imageio #noqa\n\nimport jax #noqa\nimport jax.numpy as jnp #noqa\nimport jax.tree_util as jtu #noqa\nimport flax #noqa\nimport flax.linen as nn #noqa\nfrom flax.training import orbax_utils #noqa\nimport distrax #noqa\nimport orbax #noqa\nimport optax #noqa\nimport imageio #noqa\nimport wandb #noqa\nimport matplotlib.pyplot as plt #noqa\n\nfrom flax import struct #noqa\nfrom flax.typing import Dtype #noqa\nfrom flax.linen.dtypes import promote_dtype #noqa\nfrom flax.linen.initializers import glorot_normal, orthogonal, zeros_init #noqa\nfrom flax.training.train_state import TrainState #noqa\nfrom flax.jax_utils import replicate, unreplicate #noqa\nfrom dataclasses import asdict, dataclass #noqa\nfrom functools import partial #noqa\n\nimport xminigrid.envs.pushworld as pushworld\nfrom xminigrid.envs.pushworld.benchmarks import Benchmark, BenchmarkAll\nfrom xminigrid.envs.pushworld.constants import Tiles, NUM_TILES, SUCCESS_REWARD, LEVEL0_ALL_SIZE\nfrom xminigrid.envs.pushworld.environment import Environment, EnvParams, EnvParamsT\nfrom xminigrid.envs.pushworld.envs.single_task_pushworld import SingleTaskPushWorldEnvironment, SingleTaskPushWorldEnvParams\nfrom xminigrid.envs.pushworld.envs.meta_task_pushworld import MetaTaskPushWorldEnvironment\n# Import level 0 \"all\" environments\nfrom xminigrid.envs.pushworld.envs.single_task_all_pushworld import SingleTaskPushWorldEnvironmentAll \nfrom xminigrid.envs.pushworld.envs.meta_task_all_pushworld import MetaTaskPushWorldEnvironmentAll\nfrom xminigrid.envs.pushworld.scripts.upload import encode_puzzle\nfrom xminigrid.envs.pushworld.wrappers import GoalObservationWrapper, GymAutoResetWrapper, Wrapper\nfrom xminigrid.envs.pushworld.types import State, TimeStep, StepType, EnvCarry, PushWorldPuzzle, PushWorldPuzzleAll\nfrom xminigrid.envs.pushworld.grid import get_obs_from_puzzle\nfrom IPython.display import Video, HTML, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:36.644349Z","iopub.execute_input":"2025-07-28T09:12:36.644691Z","iopub.status.idle":"2025-07-28T09:12:55.256636Z","shell.execute_reply.started":"2025-07-28T09:12:36.644669Z","shell.execute_reply":"2025-07-28T09:12:55.255776Z"}},"outputs":[{"name":"stderr","text":"2025-07-28 09:12:38.186327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753693958.363031      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753693958.413650      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO:2025-07-28 09:12:53,234:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nINFO:2025-07-28 09:12:53,246:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n","output_type":"stream"}],"execution_count":4},{"id":"b74c68ba","cell_type":"markdown","source":"## Networks","metadata":{}},{"id":"ebe26b36","cell_type":"code","source":"# Model adapted from minigrid baselines:\n# https://github.com/lcswillems/rl-starter-files/blob/master/model.py\n\n\nclass GRU(nn.Module):\n    hidden_dim: int\n    dtype: Optional[Dtype] = None\n    param_dtype: Dtype = jnp.float32\n\n    @nn.compact\n    def __call__(self, xs, init_state):\n        seq_len, input_dim = xs.shape\n        # this init might not be optimal, for example bias for reset gate should be -1 (for now ok)\n        Wi = self.param(\"Wi\", glorot_normal(in_axis=1, out_axis=0), (self.hidden_dim * 3, input_dim), self.param_dtype)\n        Wh = self.param(\"Wh\", orthogonal(column_axis=0), (self.hidden_dim * 3, self.hidden_dim), self.param_dtype)\n        bi = self.param(\"bi\", zeros_init(), (self.hidden_dim * 3,), self.param_dtype)\n        bn = self.param(\"bn\", zeros_init(), (self.hidden_dim,), self.param_dtype)\n\n        def _step_fn(h, x):\n            igates = jnp.split(Wi @ x + bi, 3)\n            hgates = jnp.split(Wh @ h, 3)\n\n            reset = nn.sigmoid(igates[0] + hgates[0])\n            update = nn.sigmoid(igates[1] + hgates[1])\n            new = nn.tanh(igates[2] + reset * (hgates[2] + bn))\n            next_h = (1 - update) * new + update * h\n\n            return next_h, next_h\n\n        # cast to the computation dtype\n        xs, init_state, Wi, Wh, bi, bn = promote_dtype(xs, init_state, Wi, Wh, bi, bn, dtype=self.dtype)\n\n        last_state, all_states = jax.lax.scan(_step_fn, init=init_state, xs=xs)\n        return all_states, last_state\n\n\nclass RNNModel(nn.Module):\n    hidden_dim: int\n    num_layers: int\n    dtype: Optional[Dtype] = None\n    param_dtype: Dtype = jnp.float32\n\n    @nn.compact\n    def __call__(self, xs, init_state):\n        # xs: [seq_len, input_dim]\n        # init_state: [num_layers, hidden_dim]\n        outs, states = [], []\n        for layer in range(self.num_layers):\n            xs, state = GRU(self.hidden_dim, self.dtype, self.param_dtype)(xs, init_state[layer])\n            outs.append(xs)\n            states.append(state)\n\n        # sum outputs from all layers, kinda like in ResNet\n        return jnp.array(outs).sum(0), jnp.array(states)\n\n\nBatchedRNNModel = flax.linen.vmap(\n    RNNModel, variable_axes={\"params\": None}, split_rngs={\"params\": False}, axis_name=\"batch\"\n)\n\n\nclass EmbeddingEncoder(nn.Module):\n    emb_dim: int = 16\n    dtype: Optional[Dtype] = None\n    param_dtype: Dtype = jnp.float32\n\n    @nn.compact\n    def __call__(self, img):\n        entity_emb = nn.Embed(NUM_TILES, self.emb_dim, self.dtype, self.param_dtype)\n\n        # [..., channels]\n        img_emb = entity_emb(img[..., 0])\n        return img_emb\n\n\nclass ActorCriticInput(TypedDict):\n    obs_img: jax.Array\n    obs_goal: jax.Array\n    prev_action: jax.Array\n    prev_reward: jax.Array\n\n\nclass ActorCriticRNN(nn.Module):\n    num_actions: int\n    obs_emb_dim: int = 16\n    action_emb_dim: int = 16\n    rnn_hidden_dim: int = 64\n    rnn_num_layers: int = 1\n    head_hidden_dim: int = 64\n    img_obs: bool = False\n    dtype: Optional[Dtype] = None\n    param_dtype: Dtype = jnp.float32\n\n    @nn.compact\n    def __call__(self, inputs: ActorCriticInput, hidden: jax.Array) -> tuple[distrax.Categorical, jax.Array, jax.Array]:\n        B, S = inputs[\"obs_img\"].shape[:2]\n\n        # encoder from https://github.com/lcswillems/rl-starter-files/blob/master/model.py\n        if self.img_obs:\n            img_encoder = nn.Sequential(\n                [\n                    nn.Conv(\n                        16,\n                        (3, 3),\n                        strides=2,\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                    nn.Conv(\n                        32,\n                        (3, 3),\n                        strides=2,\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                    nn.Conv(\n                        32,\n                        (3, 3),\n                        strides=2,\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                    nn.Conv(\n                        32,\n                        (3, 3),\n                        strides=2,\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                ]\n            )\n        else:\n            img_encoder = nn.Sequential(\n                [\n                    # For small dims nn.Embed is extremely slow in bf16, so we leave everything in default dtypes\n                    EmbeddingEncoder(emb_dim=self.obs_emb_dim),\n                    nn.Conv(\n                        16,\n                        (2, 2),\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                    nn.Conv(\n                        32,\n                        (2, 2),\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                    nn.Conv(\n                        64,\n                        (2, 2),\n                        padding=\"VALID\",\n                        kernel_init=orthogonal(math.sqrt(2)),\n                        dtype=self.dtype,\n                        param_dtype=self.param_dtype,\n                    ),\n                    nn.relu,\n                ]\n            )\n        action_encoder = nn.Embed(self.num_actions, self.action_emb_dim)\n        goal_encoder = nn.Dense(self.action_emb_dim, dtype=self.dtype, param_dtype=self.param_dtype)\n\n        rnn_core = BatchedRNNModel(\n            self.rnn_hidden_dim, self.rnn_num_layers, dtype=self.dtype, param_dtype=self.param_dtype\n        )\n        actor = nn.Sequential(\n            [\n                nn.Dense(\n                    self.head_hidden_dim, kernel_init=orthogonal(2), dtype=self.dtype, param_dtype=self.param_dtype\n                ),\n                nn.tanh,\n                nn.Dense(\n                    self.num_actions, kernel_init=orthogonal(0.01), dtype=self.dtype, param_dtype=self.param_dtype\n                ),\n            ]\n        )\n        critic = nn.Sequential(\n            [\n                nn.Dense(\n                    self.head_hidden_dim, kernel_init=orthogonal(2), dtype=self.dtype, param_dtype=self.param_dtype\n                ),\n                nn.tanh,\n                nn.Dense(1, kernel_init=orthogonal(1.0), dtype=self.dtype, param_dtype=self.param_dtype),\n            ]\n        )\n\n        # [batch_size, seq_len, ...]\n        obs_emb = img_encoder(inputs[\"obs_img\"].astype(jnp.int32)).reshape(B, S, -1)\n        goal_emb = goal_encoder(inputs[\"obs_goal\"])\n        act_emb = action_encoder(inputs[\"prev_action\"])\n\n        # [batch_size, seq_len, hidden_dim + 2 * act_emb_dim + 1]\n        out = jnp.concatenate([obs_emb, goal_emb, act_emb, inputs[\"prev_reward\"][..., None]], axis=-1)\n\n        # core networks\n        out, new_hidden = rnn_core(out, hidden)\n\n        # casting to full precision for the loss, as softmax/log_softmax\n        # (inside Categorical) is not stable in bf16\n        logits = actor(out).astype(jnp.float32)\n\n        dist = distrax.Categorical(logits=logits)\n        values = critic(out)\n\n        return dist, jnp.squeeze(values, axis=-1), new_hidden\n\n    def initialize_carry(self, batch_size):\n        return jnp.zeros((batch_size, self.rnn_num_layers, self.rnn_hidden_dim), dtype=self.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.257695Z","iopub.execute_input":"2025-07-28T09:12:55.257929Z","iopub.status.idle":"2025-07-28T09:12:55.283338Z","shell.execute_reply.started":"2025-07-28T09:12:55.257912Z","shell.execute_reply":"2025-07-28T09:12:55.282587Z"}},"outputs":[],"execution_count":5},{"id":"ffd67704","cell_type":"markdown","source":"## Utils","metadata":{}},{"id":"a86c4a11","cell_type":"code","source":"# utilities for PPO training and evaluation\n\n\n# Training stuff\nclass Transition(struct.PyTreeNode):\n    done: jax.Array\n    action: jax.Array\n    value: jax.Array\n    reward: jax.Array\n    log_prob: jax.Array\n    # for obs\n    obs: jax.Array\n    goal: jax.Array\n    # for rnn policy\n    prev_action: jax.Array\n    prev_reward: jax.Array\n\n\ndef calculate_gae(\n    transitions: Transition,\n    last_val: jax.Array,\n    gamma: float,\n    gae_lambda: float,\n) -> tuple[jax.Array, jax.Array]:\n    # single iteration for the loop\n    def _get_advantages(gae_and_next_value, transition):\n        gae, next_value = gae_and_next_value\n        delta = transition.reward + gamma * next_value * (1 - transition.done) - transition.value\n        gae = delta + gamma * gae_lambda * (1 - transition.done) * gae\n        return (gae, transition.value), gae\n\n    _, advantages = jax.lax.scan(\n        _get_advantages,\n        (jnp.zeros_like(last_val), last_val),\n        transitions,\n        reverse=True,\n    )\n    # advantages and values (Q)\n    return advantages, advantages + transitions.value\n\n\ndef ppo_update_networks(\n    train_state: TrainState,\n    transitions: Transition,\n    init_hstate: jax.Array,\n    advantages: jax.Array,\n    targets: jax.Array,\n    clip_eps: float,\n    vf_coef: float,\n    ent_coef: float,\n):\n    # NORMALIZE ADVANTAGES\n    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n\n    def _loss_fn(params):\n        # RERUN NETWORK\n        dist, value, _ = train_state.apply_fn(\n            params,\n            {\n                # [batch_size, seq_len, ...]\n                \"obs_img\": transitions.obs,\n                \"obs_goal\": transitions.goal,\n                \"prev_action\": transitions.prev_action,\n                \"prev_reward\": transitions.prev_reward,\n            },\n            init_hstate,\n        )\n        log_prob = dist.log_prob(transitions.action)\n\n        # CALCULATE VALUE LOSS\n        value_pred_clipped = transitions.value + (value - transitions.value).clip(-clip_eps, clip_eps)\n        value_loss = jnp.square(value - targets)\n        value_loss_clipped = jnp.square(value_pred_clipped - targets)\n        value_loss = 0.5 * jnp.maximum(value_loss, value_loss_clipped).mean()\n\n        # TODO: ablate this!\n        # value_loss = jnp.square(value - targets).mean()\n\n        # CALCULATE ACTOR LOSS\n        ratio = jnp.exp(log_prob - transitions.log_prob)\n        actor_loss1 = advantages * ratio\n        actor_loss2 = advantages * jnp.clip(ratio, 1.0 - clip_eps, 1.0 + clip_eps)\n        actor_loss = -jnp.minimum(actor_loss1, actor_loss2).mean()\n        entropy = dist.entropy().mean()\n\n        total_loss = actor_loss + vf_coef * value_loss - ent_coef * entropy\n        return total_loss, (value_loss, actor_loss, entropy)\n\n    (loss, (vloss, aloss, entropy)), grads = jax.value_and_grad(_loss_fn, has_aux=True)(train_state.params)\n    (loss, vloss, aloss, entropy, grads) = jax.lax.pmean((loss, vloss, aloss, entropy, grads), axis_name=\"devices\")\n    train_state = train_state.apply_gradients(grads=grads)\n    update_info = {\n        \"total_loss\": loss,\n        \"value_loss\": vloss,\n        \"actor_loss\": aloss,\n        \"entropy\": entropy,\n    }\n    return train_state, update_info\n\n\n# for evaluation (evaluate for N consecutive episodes, sum rewards)\n# N=1 single task, N>1 for meta-RL\nclass RolloutStats(struct.PyTreeNode):\n    reward: jax.Array = struct.field(default_factory=lambda: jnp.asarray(0.0))\n    length: jax.Array = struct.field(default_factory=lambda: jnp.asarray(0))\n    episodes: jax.Array = struct.field(default_factory=lambda: jnp.asarray(0))\n    solved: jax.Array = struct.field(default_factory=lambda: jnp.asarray(0))\n\n\n# for tracking per-episode statistics during meta-RL evaluation\nclass MetaRolloutStats(struct.PyTreeNode):\n    episode_rewards: jax.Array  # Shape: [max_episodes] - reward for each episode\n    episode_lengths: jax.Array  # Shape: [max_episodes] - length of each episode\n    episode_solved: jax.Array  # Shape: [max_episodes] - whether each episode was solved\n    total_reward: jax.Array  # Scalar - total reward across all episodes\n    num_episodes_completed: jax.Array  # Scalar - number of episodes actually completed\n\n\ndef rollout(\n    rng: jax.Array,\n    env: Environment,\n    env_params: EnvParams,\n    eval_puzzle: PushWorldPuzzle,\n    train_state: TrainState,\n    init_hstate: jax.Array,\n    num_consecutive_episodes: int = 1,\n) -> RolloutStats:\n    def _cond_fn(carry):\n        rng, stats, timestep, prev_action, prev_reward, hstate = carry\n        return jnp.less(stats.episodes, num_consecutive_episodes)\n\n    def _body_fn(carry):\n        rng, stats, timestep, prev_action, prev_reward, hstate = carry\n\n        rng, _rng = jax.random.split(rng)\n        dist, _, hstate = train_state.apply_fn(\n            train_state.params,\n            {\n                # We add single channel dimension to end of obs_img\n                \"obs_img\": timestep.observation[\"img\"][None, None, ...],\n                \"obs_goal\": timestep.observation[\"goal\"][None, None, ...],\n                \"prev_action\": prev_action[None, None, ...],\n                \"prev_reward\": prev_reward[None, None, ...],\n            },\n            hstate,\n        )\n        action = dist.sample(seed=_rng).squeeze()\n        timestep = env.step(env_params, timestep, action)\n\n        solved_flag = ((timestep.reward == SUCCESS_REWARD) & (timestep.last() == 1)).astype(jnp.int32)\n        stats = stats.replace(\n            reward=stats.reward + timestep.reward,\n            length=stats.length + 1,\n            episodes=stats.episodes + timestep.last(),\n            solved=solved_flag,\n        )\n        carry = (rng, stats, timestep, action, timestep.reward, hstate)\n        return carry\n\n    env_params = env_params.replace(puzzle=eval_puzzle)\n    timestep = env.eval_reset(env_params, rng)\n    prev_action = jnp.asarray(0)\n    prev_reward = jnp.asarray(0)\n    init_carry = (rng, RolloutStats(), timestep, prev_action, prev_reward, init_hstate)\n\n    final_carry = jax.lax.while_loop(_cond_fn, _body_fn, init_val=init_carry)\n    return final_carry[1]\n\n\ndef meta_rollout(\n    rng: jax.Array,\n    env: Environment,\n    env_params: EnvParams,\n    eval_puzzle: PushWorldPuzzle,\n    train_state: TrainState,\n    init_hstate: jax.Array,\n    num_consecutive_episodes: int = 1,\n) -> MetaRolloutStats:\n    \"\"\"Rollout that tracks statistics for each individual episode.\"\"\"\n\n    def _cond_fn(carry):\n        rng, stats, timestep, prev_action, prev_reward, hstate, current_episode_reward, current_episode_length = carry\n        return jnp.less(stats.num_episodes_completed, num_consecutive_episodes)\n\n    def _body_fn(carry):\n        rng, stats, timestep, prev_action, prev_reward, hstate, current_episode_reward, current_episode_length = carry\n\n        rng, _rng = jax.random.split(rng)\n        dist, _, hstate = train_state.apply_fn(\n            train_state.params,\n            {\n                # We add single channel dimension to end of obs_img\n                \"obs_img\": timestep.observation[\"img\"][None, None, ...],\n                \"obs_goal\": timestep.observation[\"goal\"][None, None, ...],\n                \"prev_action\": prev_action[None, None, ...],\n                \"prev_reward\": prev_reward[None, None, ...],\n            },\n            hstate,\n        )\n        action = dist.sample(seed=_rng).squeeze()\n        timestep = env.step(env_params, timestep, action)\n\n        # Update current episode accumulators\n        current_episode_reward = current_episode_reward + timestep.reward\n        current_episode_length = current_episode_length + 1\n\n        # Check if episode ended\n        episode_ended = timestep.last()\n        solved_flag = ((timestep.reward == SUCCESS_REWARD) & (episode_ended == 1)).astype(jnp.int32)\n\n        # When episode ends, store the episode stats\n        episode_idx = stats.num_episodes_completed\n        new_episode_rewards = stats.episode_rewards.at[episode_idx].set(\n            jnp.where(episode_ended, current_episode_reward, stats.episode_rewards[episode_idx])\n        )\n        new_episode_lengths = stats.episode_lengths.at[episode_idx].set(\n            jnp.where(episode_ended, current_episode_length, stats.episode_lengths[episode_idx])\n        )\n        new_episode_solved = stats.episode_solved.at[episode_idx].set(\n            jnp.where(episode_ended, solved_flag, stats.episode_solved[episode_idx])\n        )\n\n        # Update stats\n        stats = stats.replace(\n            episode_rewards=new_episode_rewards,\n            episode_lengths=new_episode_lengths,\n            episode_solved=new_episode_solved,\n            total_reward=stats.total_reward + timestep.reward,\n            num_episodes_completed=stats.num_episodes_completed + episode_ended,\n        )\n\n        # Reset episode accumulators when episode ends\n        current_episode_reward = jnp.where(episode_ended, 0.0, current_episode_reward)\n        current_episode_length = jnp.where(episode_ended, 0, current_episode_length)\n\n        carry = (rng, stats, timestep, action, timestep.reward, hstate, current_episode_reward, current_episode_length)\n        return carry\n\n    # Initialize episode tracking arrays\n    episode_rewards = jnp.zeros(num_consecutive_episodes)\n    episode_lengths = jnp.zeros(num_consecutive_episodes, dtype=jnp.int32)\n    episode_solved = jnp.zeros(num_consecutive_episodes, dtype=jnp.int32)\n\n    initial_stats = MetaRolloutStats(\n        episode_rewards=episode_rewards,\n        episode_lengths=episode_lengths,\n        episode_solved=episode_solved,\n        total_reward=jnp.asarray(0.0),\n        num_episodes_completed=jnp.asarray(0),\n    )\n\n    env_params = env_params.replace(puzzle=eval_puzzle)\n    timestep = env.eval_reset(env_params, rng)\n    prev_action = jnp.asarray(0)\n    prev_reward = jnp.asarray(0)\n    current_episode_reward = jnp.asarray(0.0)\n    current_episode_length = jnp.asarray(0)\n\n    init_carry = (\n        rng,\n        initial_stats,\n        timestep,\n        prev_action,\n        prev_reward,\n        init_hstate,\n        current_episode_reward,\n        current_episode_length,\n    )\n\n    final_carry = jax.lax.while_loop(_cond_fn, _body_fn, init_val=init_carry)\n    return final_carry[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.285243Z","iopub.execute_input":"2025-07-28T09:12:55.285691Z","iopub.status.idle":"2025-07-28T09:12:55.353137Z","shell.execute_reply.started":"2025-07-28T09:12:55.285661Z","shell.execute_reply":"2025-07-28T09:12:55.352498Z"}},"outputs":[],"execution_count":6},{"id":"f6e168f8","cell_type":"markdown","source":"## Training","metadata":{}},{"id":"35124caa","cell_type":"code","source":"# this will be default in new jax versions anyway\n# jax.config.update(\"jax_threefry_partitionable\", True)\n\n\n@dataclass\nclass TrainConfig:\n    project: str = \"PushWorld\"\n    group: str = \"default\"\n    name: str = \"single-task-ppo-pushworld\"\n    benchmark_id: str = \"level0_mini\"\n    track: bool = False\n    checkpoint_path: Optional[str] = None\n    upload_model: bool = False\n\n    train_test_same: bool = False\n    num_train: Optional[int] = None\n    num_test: Optional[int] = None\n\n    img_obs: bool = False\n    obs_emb_dim: int = 16\n    action_emb_dim: int = 16\n    rnn_hidden_dim: int = 1024\n    rnn_num_layers: int = 1\n    head_hidden_dim: int = 256\n    enable_bf16: bool = False\n    num_envs: int = 8192\n    num_steps: int = 16\n    update_epochs: int = 1\n    num_minibatches: int = 16\n    total_timesteps: int = 1_000_000\n    lr: float = 0.001\n    clip_eps: float = 0.2\n    gamma: float = 0.99\n    gae_lambda: float = 0.95\n    ent_coef: float = 0.01\n    vf_coef: float = 0.5\n    max_grad_norm: float = 0.5\n    eval_episodes: int = 80\n    seed: int = 42\n    puzzle_seed: int = 42\n    eval_seed: int = 42\n\n    def __post_init__(self):\n        num_devices = jax.local_device_count()\n        self.num_envs_per_device = self.num_envs // num_devices\n        self.total_timesteps_per_device = self.total_timesteps // num_devices\n        self.eval_episodes_per_device = self.eval_episodes // num_devices\n        assert self.num_envs % num_devices == 0\n        self.num_updates = self.total_timesteps_per_device // self.num_steps // self.num_envs_per_device\n        print(f\"Num devices: {num_devices}, Num updates: {self.num_updates}\")\n\n\ndef make_states(config: TrainConfig):\n    # for learning rate scheduling\n    def linear_schedule(count):\n        frac = 1.0 - (count // (config.num_minibatches * config.update_epochs)) / config.num_updates\n        return config.lr * frac\n\n    env = SingleTaskPushWorldEnvironment()\n    env_params = env.default_params()\n    env = GymAutoResetWrapper(env)\n    env = GoalObservationWrapper(env)\n\n    benchmark = pushworld.load_benchmark(config.benchmark_id)\n\n    puzzle_rng = jax.random.key(config.puzzle_seed)\n    train_rng, test_rng = jax.random.split(puzzle_rng)\n\n    if config.num_train is not None:\n        assert config.num_train <= benchmark.num_train_puzzles(), (\n            \"num_train is larger than num train available in benchmark\"\n        )\n        perm = jax.random.permutation(train_rng, benchmark.num_train_puzzles())\n        idxs = perm[: config.num_train]\n        benchmark = benchmark.replace(train_puzzles=benchmark.train_puzzles[idxs])\n    else:\n        config.num_train = benchmark.num_train_puzzles()\n\n    if config.num_test is not None:\n        assert config.num_test <= benchmark.num_test_puzzles(), (\n            \"num_test is larger than num test available in benchmark\"\n        )\n        perm = jax.random.permutation(test_rng, benchmark.num_test_puzzles())\n        idxs = perm[: config.num_test]\n        benchmark = benchmark.replace(test_puzzles=benchmark.test_puzzles[idxs])\n    else:\n        config.num_test = benchmark.num_test_puzzles()\n\n    if config.train_test_same:\n        benchmark = benchmark.replace(test_puzzles=benchmark.train_puzzles)\n        config.num_test = config.num_train\n\n\n    rng = jax.random.key(config.seed)\n    rng, _rng = jax.random.split(rng)\n\n    network = ActorCriticRNN(\n        num_actions=env.num_actions(env_params),\n        obs_emb_dim=config.obs_emb_dim,\n        action_emb_dim=config.action_emb_dim,\n        rnn_hidden_dim=config.rnn_hidden_dim,\n        rnn_num_layers=config.rnn_num_layers,\n        head_hidden_dim=config.head_hidden_dim,\n        img_obs=config.img_obs,\n        dtype=jnp.bfloat16 if config.enable_bf16 else None,\n    )\n\n    shapes = env.observation_shape(env_params)\n\n    init_obs = {\n        \"obs_img\": jnp.zeros((config.num_envs_per_device, 1, *shapes[\"img\"])),\n        \"obs_goal\": jnp.zeros((config.num_envs_per_device, 1, shapes[\"goal\"])),\n        \"prev_action\": jnp.zeros((config.num_envs_per_device, 1), dtype=jnp.int32),\n        \"prev_reward\": jnp.zeros((config.num_envs_per_device, 1)),\n    }\n    init_hstate = network.initialize_carry(batch_size=config.num_envs_per_device)\n\n    network_params = network.init(_rng, init_obs, init_hstate)\n    tx = optax.chain(\n        optax.clip_by_global_norm(config.max_grad_norm),\n        optax.inject_hyperparams(optax.adam)(learning_rate=linear_schedule, eps=1e-8),  # eps=1e-5\n    )\n    train_state = TrainState.create(apply_fn=network.apply, params=network_params, tx=tx)\n\n    return rng, env, env_params, benchmark, init_hstate, train_state\n\n\ndef make_train(\n    env: Environment,\n    env_params: EnvParams,\n    benchmark: Benchmark,\n    config: TrainConfig,\n):\n    @partial(jax.pmap, axis_name=\"devices\")\n    def train(\n        rng: jax.Array,\n        train_state: TrainState,\n        init_hstate: jax.Array,\n    ):\n        rng, _rng = jax.random.split(rng)\n        reset_rng = jax.random.split(_rng, config.num_envs_per_device)\n\n        puzzle_env_params = env_params.replace(benchmark=benchmark)\n\n        timestep = jax.vmap(env.reset, in_axes=(None, 0))(puzzle_env_params, reset_rng)\n        prev_action = jnp.zeros(config.num_envs_per_device, dtype=jnp.int32)\n        prev_reward = jnp.zeros(config.num_envs_per_device)\n\n        # TRAIN LOOP\n        def _update_step(runner_state, update_idx):\n            # jax.debug.print(\"Update step: {}\", update_idx)\n\n            # COLLECT TRAJECTORIES\n            def _env_step(runner_state, _):\n                rng, train_state, prev_timestep, prev_action, prev_reward, prev_hstate = runner_state\n\n                rng, _rng = jax.random.split(rng)\n                dist, value, hstate = train_state.apply_fn(\n                    train_state.params,\n                    {\n                        # [batch_size, seq_len=1, ...]\n                        \"obs_img\": prev_timestep.observation[\"img\"][:, None],\n                        \"obs_goal\": prev_timestep.observation[\"goal\"][:, None],\n                        \"prev_action\": prev_action[:, None],\n                        \"prev_reward\": prev_reward[:, None],\n                    },\n                    prev_hstate,\n                )\n                action, log_prob = dist.sample_and_log_prob(seed=_rng)\n                action, value, log_prob = action.squeeze(1), value.squeeze(1), log_prob.squeeze(1)\n\n                timestep = jax.vmap(env.step, in_axes=(None, 0, 0))(puzzle_env_params, prev_timestep, action)\n                transition = Transition(\n                    done=timestep.last(),\n                    action=action,\n                    value=value,\n                    reward=timestep.reward,\n                    log_prob=log_prob,\n                    obs=prev_timestep.observation[\"img\"],\n                    goal=prev_timestep.observation[\"goal\"],\n                    prev_action=prev_action,\n                    prev_reward=prev_reward,\n                )\n                runner_state = (rng, train_state, timestep, action, timestep.reward, hstate)\n                return runner_state, transition\n\n            initial_hstate = runner_state[-1]\n            runner_state, transitions = jax.lax.scan(_env_step, runner_state, None, config.num_steps)\n\n            rng, train_state, timestep, prev_action, prev_reward, hstate = runner_state\n            _, last_val, _ = train_state.apply_fn(\n                train_state.params,\n                {\n                    \"obs_img\": timestep.observation[\"img\"][:, None],\n                    \"obs_goal\": timestep.observation[\"goal\"][:, None],\n                    \"prev_action\": prev_action[:, None],\n                    \"prev_reward\": prev_reward[:, None],\n                },\n                hstate,\n            )\n            advantages, targets = calculate_gae(transitions, last_val.squeeze(1), config.gamma, config.gae_lambda)\n\n            # UPDATE NETWORK\n            def _update_epoch(update_state, _):\n                def _update_minbatch(train_state, batch_info):\n                    init_hstate, transitions, advantages, targets = batch_info\n                    new_train_state, update_info = ppo_update_networks(\n                        train_state=train_state,\n                        transitions=transitions,\n                        init_hstate=init_hstate.squeeze(1),\n                        advantages=advantages,\n                        targets=targets,\n                        clip_eps=config.clip_eps,\n                        vf_coef=config.vf_coef,\n                        ent_coef=config.ent_coef,\n                    )\n                    return new_train_state, update_info\n\n                rng, train_state, init_hstate, transitions, advantages, targets = update_state\n\n                rng, _rng = jax.random.split(rng)\n                permutation = jax.random.permutation(_rng, config.num_envs_per_device)\n                batch = (init_hstate, transitions, advantages, targets)\n                batch = jtu.tree_map(lambda x: x.swapaxes(0, 1), batch)\n\n                shuffled_batch = jtu.tree_map(lambda x: jnp.take(x, permutation, axis=0), batch)\n                minibatches = jtu.tree_map(\n                    lambda x: jnp.reshape(x, (config.num_minibatches, -1) + x.shape[1:]), shuffled_batch\n                )\n                train_state, update_info = jax.lax.scan(_update_minbatch, train_state, minibatches)\n\n                update_state = (rng, train_state, init_hstate, transitions, advantages, targets)\n                return update_state, update_info\n\n            init_hstate = initial_hstate[None, :]\n            update_state = (rng, train_state, init_hstate, transitions, advantages, targets)\n            update_state, loss_info = jax.lax.scan(_update_epoch, update_state, None, config.update_epochs)\n\n            loss_info = jtu.tree_map(lambda x: x.mean(-1).mean(-1), loss_info)\n\n            rng, train_state = update_state[:2]\n\n            eval_reset_rng = jax.random.key(config.eval_seed)\n            eval_test_rng, eval_train_rng = jax.random.split(eval_reset_rng)\n            assert config.num_test is not None, \"num_test must be set for evaluation\"\n            assert config.num_train is not None, \"num_train must be set for evaluation\"\n\n            eval_test_reset_rng = jax.random.split(eval_test_rng, num=config.num_test)\n            eval_test_puzzles = benchmark.get_test_puzzles()\n            eval_test_stats = jax.vmap(rollout, in_axes=(0, None, None, 0, None, None, None))(\n                eval_test_reset_rng,\n                env,\n                puzzle_env_params,\n                eval_test_puzzles,\n                train_state,\n                # TODO: make this as a static method mb?\n                jnp.zeros((1, config.rnn_num_layers, config.rnn_hidden_dim)),\n                1,\n            )\n            eval_test_stats = jax.lax.pmean(eval_test_stats, axis_name=\"devices\")\n\n            eval_train_reset_rng = jax.random.split(eval_train_rng, num=config.num_train)\n            eval_train_puzzles = benchmark.get_train_puzzles()\n            eval_train_stats = jax.vmap(rollout, in_axes=(0, None, None, 0, None, None, None))(\n                eval_train_reset_rng,\n                env,\n                puzzle_env_params,\n                eval_train_puzzles,\n                train_state,\n                # TODO: make this as a static method mb?\n                jnp.zeros((1, config.rnn_num_layers, config.rnn_hidden_dim)),\n                1,\n            )\n            eval_train_stats = jax.lax.pmean(eval_train_stats, axis_name=\"devices\")\n\n            loss_info.update(\n                {\n                    \"eval_test/returns_mean\": eval_test_stats.reward.mean(0),\n                    \"eval_test/lengths\": eval_test_stats.length.mean(0),\n                    \"eval_test/solved_percentage\": eval_test_stats.solved.sum(0) / config.num_test,\n                    \"eval_train/returns_mean\": eval_train_stats.reward.mean(0),\n                    \"eval_train/lengths\": eval_train_stats.length.mean(0),\n                    \"eval_train/solved_percentage\": eval_train_stats.solved.sum(0) / config.num_train,\n                    \"lr\": train_state.opt_state[-1].hyperparams[\"learning_rate\"],\n                }\n            )\n            runner_state = (rng, train_state, timestep, prev_action, prev_reward, hstate)\n            return runner_state, loss_info\n\n        runner_state = (rng, train_state, timestep, prev_action, prev_reward, init_hstate)\n        update_indices = jnp.arange(config.num_updates)\n        runner_state, loss_info = jax.lax.scan(_update_step, runner_state, update_indices, config.num_updates)\n        return {\"runner_state\": runner_state[1], \"loss_info\": loss_info}\n\n    return train\n\n\ndef train(config: TrainConfig):\n    # removing existing checkpoints if any\n    if config.checkpoint_path is not None and os.path.exists(config.checkpoint_path):\n        shutil.rmtree(config.checkpoint_path)\n\n    rng, env, env_params, benchmark, init_hstate, train_state = make_states(config)\n\n    rng = jax.random.split(rng, num=jax.local_device_count())\n    train_state = replicate(train_state, jax.local_devices())\n    init_hstate = replicate(init_hstate, jax.local_devices())\n\n    print(\"Compiling...\")\n    t = time.time()\n    train_fn = make_train(env, env_params, benchmark, config)\n    train_fn = train_fn.lower(rng, train_state, init_hstate).compile()\n    elapsed_time = time.time() - t\n    print(f\"Done in {elapsed_time:.2f}s.\")\n\n    print(\"Training...\")\n    t = time.time()\n    train_info = jax.block_until_ready(train_fn(rng, train_state, init_hstate))\n    elapsed_time = time.time() - t\n    print(f\"Done in {elapsed_time:.2f}s\")\n\n    return unreplicate(train_info), elapsed_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.353811Z","iopub.execute_input":"2025-07-28T09:12:55.353985Z","iopub.status.idle":"2025-07-28T09:12:55.389034Z","shell.execute_reply.started":"2025-07-28T09:12:55.353969Z","shell.execute_reply":"2025-07-28T09:12:55.388304Z"}},"outputs":[],"execution_count":7},{"id":"501ee9f9","cell_type":"markdown","source":"## Processing","metadata":{}},{"id":"ca58f587","cell_type":"code","source":"def processing(config: TrainConfig, train_info, elapsed_time):\n    print(\"Logging...\")\n    loss_info = train_info[\"loss_info\"]\n\n    if config.track or config.upload_model:\n        run = wandb.init(\n            project=config.project,\n            group=config.group,\n            name=config.name,\n            config=asdict(config),\n            save_code=True,\n        )\n\n    if config.track:\n        total_transitions = 0\n        for i in range(config.num_updates):\n            total_transitions += config.num_steps * config.num_envs_per_device * jax.local_device_count()\n            info = jtu.tree_map(lambda x: x[i].item(), loss_info)\n            info[\"transitions\"] = total_transitions\n            wandb.log(info)\n\n        run.summary[\"training_time\"] = elapsed_time\n        run.summary[\"steps_per_second\"] = (config.total_timesteps_per_device * jax.local_device_count()) / elapsed_time\n\n    if config.checkpoint_path is not None:\n        checkpoint = {\"config\": asdict(config), \"params\": train_info[\"runner_state\"].params}\n        orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n        save_args = orbax_utils.save_args_from_target(checkpoint)\n        orbax_checkpointer.save(config.checkpoint_path, checkpoint, save_args=save_args)\n\n        if config.upload_model:\n            artifact = wandb.Artifact(\n                name=f\"model-checkpoint-{run.id}\", type=\"model\", description=\"Trained model checkpoint\"\n            )\n            artifact.add_dir(config.checkpoint_path)  # Add entire checkpoint directory\n            run.log_artifact(artifact)\n\n    if config.track or config.upload_model:\n        run.finish()\n\n    print(\"Final test set return: \", float(loss_info[\"eval_test/returns_mean\"][-1]))\n    print(\"Final test set solved percentage: \", float(loss_info[\"eval_test/solved_percentage\"][-1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.389946Z","iopub.execute_input":"2025-07-28T09:12:55.390225Z","iopub.status.idle":"2025-07-28T09:12:55.405843Z","shell.execute_reply.started":"2025-07-28T09:12:55.390200Z","shell.execute_reply":"2025-07-28T09:12:55.405225Z"}},"outputs":[],"execution_count":8},{"id":"152ca59d","cell_type":"markdown","source":"## Evaluation","metadata":{}},{"id":"56b1c253","cell_type":"code","source":"def hex_to_rgb(hex_string: str):\n    \"\"\"Converts a standard 6-digit hex color into a tuple of decimal\n    (red, green, blue) values.\"\"\"\n    return tuple(int(hex_string[i : i + 2], 16) for i in (0, 2, 4))\n\n\nsymbol_to_rgb = {\n    0: hex_to_rgb(\"FFFFFF\"),  # empty → white\n    1: hex_to_rgb(\"00DC00\"),  # agent → \"00DC00\"\n    2: hex_to_rgb(\"469BFF\"),  # movable → \"469BFF\"\n    3: hex_to_rgb(\"DC0000\"),  # movable_goal → \"DC0000\"\n    4: hex_to_rgb(\"0A0A0A\"),  # wall → \"0A0A0A\"\n}\n\n\ndef text_to_rgb(goal_pos, grid):\n    \"\"\"grid: 2-D array of str, shape (H, W)\"\"\"\n    h, w = grid.shape\n    img = np.zeros((h, w, 3), dtype=np.uint8)\n    for sym, rgb in symbol_to_rgb.items():\n        mask = grid == sym\n        img[mask] = rgb\n\n    if grid[goal_pos[1], goal_pos[0]] == Tiles.EMPTY:\n        img[goal_pos[1], goal_pos[0]] = hex_to_rgb(\"FF7F7F\")  # light red\n\n    # upscale (optional) so each tile is, say, 16×16 pixels\n    img = np.kron(img, np.ones((64, 64, 1), dtype=np.uint8))\n    return img\n\n\ndef text_to_rgb_all(observation: jax.Array):\n    # I want you to render the observation into a grid\n    # Observation is a jax.Array, shape (H, W, 8),\n    # Where 8 is the number of channels.\n    # Each channel represents a different object, which should have its own color.\n    # This is the order of the channels:\n    # channels.append(create_channel(state.a))  # agent\n    # channels.append(create_channel(state.m1))  # movable 1\n    # channels.append(create_channel(state.m2))  # movable 2\n    # channels.append(create_channel(state.m3))  # movable 3\n    # channels.append(create_channel(state.m4))  # movable 4\n    # channels.append(create_channel(puzzle.g1))  # goal 1\n    # channels.append(create_channel(puzzle.g2))  # goal 2\n    # channels.append(create_channel(puzzle.w))  # walls\n\n    # Movables that have associated goals should be given the \"movable_goal\" color,\n    # movables that do not should just be given the \"movable\" color.\n\n    # Convert to numpy for easier processing\n    obs_np = np.array(observation)\n    h, w = obs_np.shape[:2]\n\n    # Create RGB image initialized to white (empty spaces)\n    rgb_img = np.zeros((h, w, 3), dtype=np.uint8)\n    rgb_img.fill(255)  # white background\n\n    # Channel indices\n    AGENT_CH = 0\n    M1_CH, M2_CH, M3_CH, M4_CH = 1, 2, 3, 4\n    G1_CH, G2_CH = 5, 6\n    WALL_CH = 7\n\n    # Extract individual channels\n    agent = obs_np[:, :, AGENT_CH]\n    m1 = obs_np[:, :, M1_CH]\n    m2 = obs_np[:, :, M2_CH]\n    m3 = obs_np[:, :, M3_CH]\n    m4 = obs_np[:, :, M4_CH]\n    g1 = obs_np[:, :, G1_CH]\n    g2 = obs_np[:, :, G2_CH]\n    walls = obs_np[:, :, WALL_CH]\n\n    # Render walls first (bottom layer)\n    wall_mask = walls > 0\n    rgb_img[wall_mask] = symbol_to_rgb[4]  # black\n\n    # Render goals (light red for empty goals)\n    g1_mask = g1 > 0\n    g2_mask = g2 > 0\n    rgb_img[g1_mask] = hex_to_rgb(\"FF7F7F\")  # light red\n    rgb_img[g2_mask] = hex_to_rgb(\"FF7F7F\")  # light red\n\n    # Render movables with appropriate colors\n    # Goal-movable pairing is dynamic based on which goals exist:\n    # - If only g1 exists: m1 is the goal movable, m2/m3/m4 are regular movables\n    # - If both g1 and g2 exist: m1 and m2 are goal movables, m3/m4 are regular movables\n\n    # Check which goals exist\n    g1_exists = np.any(g1_mask)\n    g2_exists = np.any(g2_mask)\n\n    # m1: movable_goal color if on g1. g1 is guaranteed to always exist.\n    m1_mask = m1 > 0\n    rgb_img[m1_mask] = symbol_to_rgb[3]  # movable_goal (red)\n\n    # m2: movable_goal color if on g2 (when g2 exists), otherwise movable color\n    m2_mask = m2 > 0\n    if g2_exists:\n        rgb_img[m2_mask] = symbol_to_rgb[3]  # movable_goal (red)\n    else:\n        rgb_img[m2_mask] = symbol_to_rgb[2]  # movable (blue)\n\n    # m3 and m4: always regular movable color (no associated goals)\n    m3_mask = m3 > 0\n    m4_mask = m4 > 0\n    rgb_img[m3_mask] = symbol_to_rgb[2]  # movable (blue)\n    rgb_img[m4_mask] = symbol_to_rgb[2]  # movable (blue)\n\n    # Render agent on top\n    agent_mask = agent > 0\n    rgb_img[agent_mask] = symbol_to_rgb[1]  # agent (green)\n\n    # Upscale for better visibility (64x64 pixels per tile)\n    upscaled_img = np.kron(rgb_img, np.ones((64, 64, 1), dtype=np.uint8))\n\n    return upscaled_img\n\n\ndef load_checkpoint_params(run_id):\n    api = wandb.Api()\n\n    # Construct the full artifact path\n    artifact_path = f\"kimyoungjin-nus/PushWorld/model-checkpoint-{run_id}:latest\"\n\n    # Fetch the artifact object directly\n    artifact = api.artifact(artifact_path)\n\n    # Download its contents\n    artifact_dir = artifact.download()\n\n    orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n    checkpoint = orbax_checkpointer.restore(artifact_dir)\n\n    print(f\"Successfully loaded checkpoint at {artifact_dir}\")\n    return checkpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.406678Z","iopub.execute_input":"2025-07-28T09:12:55.406894Z","iopub.status.idle":"2025-07-28T09:12:55.425056Z","shell.execute_reply.started":"2025-07-28T09:12:55.406879Z","shell.execute_reply":"2025-07-28T09:12:55.424244Z"}},"outputs":[],"execution_count":9},{"id":"2223fafb","cell_type":"code","source":"def evaluate_single(train_info, config, puzzles, video_name, eval_seed):\n    # We're only going to sample from test anyway\n    benchmark = Benchmark(\n        train_puzzles=puzzles,\n        test_puzzles=puzzles,\n    )\n\n    env = SingleTaskPushWorldEnvironment()\n    env_params = env.default_params()\n    env_params = env_params.replace(benchmark=benchmark)\n    env = GoalObservationWrapper(env)\n\n    params = train_info[\"runner_state\"].params\n    model = ActorCriticRNN(\n        num_actions=env.num_actions(env_params),\n        action_emb_dim=config.action_emb_dim,\n        rnn_hidden_dim=config.rnn_hidden_dim,\n        rnn_num_layers=config.rnn_num_layers,\n        head_hidden_dim=config.head_hidden_dim,\n        img_obs=config.img_obs,\n    )\n\n    # jitting all functions\n    apply_fn, reset_fn, step_fn = jax.jit(model.apply), jax.jit(env.reset), jax.jit(env.step)\n\n    # for logging\n    total_reward = 0\n    rendered_imgs = []\n\n    rng = jax.random.key(eval_seed)\n    rng, _rng = jax.random.split(rng)\n\n    # initial inputs\n    hidden = model.initialize_carry(1)\n    prev_reward = jnp.asarray(0)\n    prev_action = jnp.asarray(0)\n\n    timestep = reset_fn(env_params, _rng)\n    rendered_imgs.append(text_to_rgb(timestep.state.goal_pos, timestep.observation[\"img\"].squeeze(-1)))\n\n    while not timestep.last():\n        rng, _rng = jax.random.split(rng)\n        dist, _, hidden = apply_fn(\n            params,\n            {\n                \"obs_img\": timestep.observation[\"img\"][None, None, ...],\n                \"obs_goal\": timestep.observation[\"goal\"][None, None, ...],\n                \"prev_action\": prev_action[None, None, ...],\n                \"prev_reward\": prev_reward[None, None, ...],\n            },\n            hidden,\n        )\n        action = dist.sample(seed=_rng).squeeze()\n\n        timestep = step_fn(env_params, timestep, action)\n        prev_action = action\n        prev_reward = timestep.reward\n\n        total_reward += timestep.reward.item()\n        rendered_imgs.append(text_to_rgb(timestep.state.goal_pos, timestep.observation[\"img\"].squeeze(-1)))\n\n    imageio.mimsave(f\"{video_name}.mp4\", rendered_imgs, fps=16, format=\"mp4\")\n    return total_reward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.425767Z","iopub.execute_input":"2025-07-28T09:12:55.425974Z","iopub.status.idle":"2025-07-28T09:12:55.439321Z","shell.execute_reply.started":"2025-07-28T09:12:55.425958Z","shell.execute_reply":"2025-07-28T09:12:55.438715Z"}},"outputs":[],"execution_count":10},{"id":"cbf56e98","cell_type":"markdown","source":"## Run Training","metadata":{}},{"id":"91a64301","cell_type":"code","source":"import os, wandb\nos.environ[\"WANDB_API_KEY\"] = \"cb4c79753c4063df05910b4f58818841843fb15b\" # fill in\nwandb.login(key=os.environ[\"WANDB_API_KEY\"], relogin=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:12:55.439936Z","iopub.execute_input":"2025-07-28T09:12:55.440142Z","iopub.status.idle":"2025-07-28T09:13:01.971321Z","shell.execute_reply.started":"2025-07-28T09:12:55.440127Z","shell.execute_reply":"2025-07-28T09:13:01.970747Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimyoungjin1001\u001b[0m (\u001b[33mkimyoungjin-nus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":11},{"id":"fad1e4d3","cell_type":"code","source":"config = TrainConfig(\n    benchmark_id=\"level0_transformed_base\", \n    total_timesteps=200_000_000, \n    num_envs=8192, \n    num_steps=100,\n    name='ppo-level0-base-244steps',\n    track=True,\n    upload_model=True,\n    checkpoint_path=\"/checkpoint\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T09:13:32.654522Z","iopub.execute_input":"2025-07-28T09:13:32.655211Z","iopub.status.idle":"2025-07-28T09:13:32.660314Z","shell.execute_reply.started":"2025-07-28T09:13:32.655186Z","shell.execute_reply":"2025-07-28T09:13:32.659372Z"}},"outputs":[{"name":"stdout","text":"Num devices: 1, Num updates: 244\n","output_type":"stream"}],"execution_count":12},{"id":"a42e0041","cell_type":"code","source":"train_info, elapsed_time = train(config)\nprocessing(config, train_info, elapsed_time)","metadata":{},"outputs":[],"execution_count":null}]}